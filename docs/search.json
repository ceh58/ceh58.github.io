[
  {
    "objectID": "posts/2024-12-01-thomas-fire/index.html",
    "href": "posts/2024-12-01-thomas-fire/index.html",
    "title": "Analyzing the Impact of the Thomas Fire in Python",
    "section": "",
    "text": "About\nThe Thomas Fire burned over 280,000 acres (about 440 square miles) across Ventura and Santa Barbara counties in December 2017, the largest wildfire in modern California history at the time. The main catalyst for the fire’s rapid spread was unseasonably strong Santa Ana wind that brought warm air and low humidity. In the end, 1,063 structures were lost, over 104,607 residents were forced to leave their homes, and damages totaled over $2.2 billion. Lasting environmental effects of the fire included poor air quality and mudflows during the successive rainy season as a result of the vegetation loss1.\nThe first analysis2 uses imagery taken by Landsat 8 on January 16, 2018 to highlight the burn scar left by the Thomas Fire after it was considered fully contained (January 12, 2018). By assigning infrared bands to visible colors (short wave infrared to ‘red’, near infrared to ‘green’, and red to ‘blue’), we can easily distinguish the burn scar from the surrounding vegetation. Bare earth/dead vegetation reflects swir (short wave infrared), appearing red, and healthy vegetation reflects nir (near infrared), appearing green, in the false color image3. We can then match the burn scar with the Thomas Fire perimeter, isolated from a fire perimeters dataset.\nThe second analysis4 uses Air Quality Index (AQI) data from the US Environmental Protection Agency to visualize the impact on the AQI of the 2017 Thomas Fire.\n\n\nHighlights\nAnalysis 1:\n\nThis task explores assigning infrared bands to visible colors to obtain false color imagery.\nNecessary steps include cleaning rasters with the rioxarray package as well as filtering geo-dataframes with geopandas package.\nIt is essential to match the Coordinate Reference Systems (CRSs) of shapefiles and rasters to obtain the final figure.\n\nAnalysis 2:\n\nThis task uses pandas to wrangle dataframes.\nIt requires working with various datatypes, such as dates.\nUsing matplotlib.pyplot, we can create engaging visualizations!\n\n\n\nRepository\nMore detailed information can be found on my Thomas Fire GitHub Repository.\n\nRepository structure:\n├── data\n│  ├── thomas_fire.cpg\n│  ├── thoams_fire.dbf\n│  ├── thomas_fire.prj\n│  ├── thomas_fire.shp\n│  └── thomas_fire.shx\n├── .gitignore\n├── README.md\n├── aqi-analysis.ipynb\n├── false-color-analysis.ipynb\n└── fire-perimeter.ipynb\n\n\n\nDataset Descriptions\nLandsat Data:\nThe landsat dataset used in this analysis is a cleaned, simplified collection of bands (red, green, blue, nir, swir) from Landsat Collection 2 Level-2 (collected by Landsat 8 satellite) that was prepared specifically for this project.\nFire Perimeters Data:\nThe fire perimeters dataset is an open-source dataset that contains information about the spatial distrubtion of past fires in California published by the State of California (and downloaded as a shapefile).\nAQI Data:\nThis analysis directly imports the US AQI (by county) data for 2017 and 2018 via zip file. Both datasets will need to be filtered for Santa Barbara county.\n\n\nAnalysis\n\nPart 1\nDerived from fire-perimeter.ipynb.\nFirst, import all necessary packages.\nimport os\nimport pandas as pd\nimport geopandas as gpd\nimport xarray as xr\nThen, import the fire perimeters dataset (shapefile) and filter for the 2017 Thomas Fire. Save the filtered dataset in a format of your choice. I chose to save it as a shapefile due to its versatility and familiarity.\nNote: I saved the full fire perimeters dataset in my data/ folder in a separate no_push/ folder that was added to my .gitignore due to the size of the data.\n# Create filepath\nfp = os.path.join(\"data\", \"no_push\", \"California_Fire_Perimeters_(all).shp\")\n\n# Read in data\nfire_perimeter = gpd.read_file(fp)\n\n# Lower column names\nfire_perimeter.rename(columns=str.lower, inplace=True)\n\n# Select Thomas Fire boundary by filtering for name and year\nthomas_fire = fire_perimeter.loc[(fire_perimeter['fire_name'] == \"THOMAS\") & \n                                 (fire_perimeter['year_']== 2017)]\n                                 \n# Save Thomas Fire boundary as a shapefile\nthomas_fire.to_file(os.path.join(\"data\", \"thomas_fire.shp\"))\n\n\nPart 2\nDerived from false-color-analysis.ipynb.\nFirst, import all necessary packages.\nimport os\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport geopandas as gpd\nimport xarray as xr\nimport rioxarray as rioxr\nimport numpy as np\nNext, import the landsat data (which has been pre-processed and saved on the server at the given filepath: /courses/EDS220/data/hwk4_landsat_data\", \"landsat8-2018-01-26-sb-simplified.nc).\n# Import data\nfp = os.path.join(\"/courses/EDS220/data/hwk4_landsat_data\", \"landsat8-2018-01-26-sb-simplified.nc\")\nlandsat = rioxr.open_rasterio(fp)\nlandsat\n\n\n\n\n\nNotice that the raster has a dimension, band, of size one. This dimension is not necessary, so we will use the squeeze() and drop_vars() functions to remove it.\n# Drop the 'band' dimension\nlandsat = landsat.squeeze().drop_vars('band')\n\n# Confirm 'band' was dropped\nprint(landsat.dims, landsat.coords)\nConfirm that band no longer appears on the list of dimensions (landsat.dims).\n\n\n\n\n\nNow we can plot a true color image. To do this, we must select the ‘red’, ‘green’, and ‘blue’ bands, in that order, and assign them to the ‘red’, ‘green’, and ‘blue’ colors using .imshow().\n# Select 'red', 'green', and 'blue' variables and plot\nlandsat[['red', 'green', 'blue']].to_array().plot.imshow()\nSince there are outliers in these data, the initial plot is black and white and gives us the following warning message:\n\n\n\n\n\nIn order to de-weight the outliers and properly scale each band, we will set the robust parameter in .imshow() to True.\n# Adjust the scale for a true color plot\nlandsat[['red', 'green', 'blue']].to_array().plot.imshow(robust = True)\nThis produces our true color image:\n\n\n\n\n\nTo create our false color image, we must assign the short wave infrared band (‘swir22’) to the ‘red’ color, the near infrared band (‘nir08’) to the ‘green’ color, and ‘red’ band to the ‘blue’ color using the same function.\n# Create a false color image\nlandsat[['swir22', 'nir08', 'red']].to_array().plot.imshow(robust = True)\nThe result is our false color image:\n\n\n\n\n\nFinally, we can create our figure.\nIn order to do this, we must import the Thomas Fire perimeter shapefile we previously saved in Part 1, thomas_fire.shp, and check to see that the CRS of the shapefile matches that of the landsat data using .crs (from the geopandas package) for the shapefile and .rio.crs (from the rioxarray package) for the raster.\n# Import Thomas Fire shapefile\nthomas_fire = gpd.read_file(os.path.join(\"data\", \"thomas_fire.shp\"))\n\n# Make sure CRSs match\nif thomas_fire.crs == landsat.rio.crs:\n    print(\"CRSs match!\")\nelse:\n    landsat = landsat.rio.reproject(thomas_fire.crs)\n    assert landsat.rio.crs == thomas_fire.crs\n    print(\"We matched the CRSs!\")\n\n\n\n\n\nTo plot the image, we must create an aspect ratio to correctly display the size. The aspect ratio is the width/height.\n# Map the false color image with the fire perimeter\nlandsat_aspect_ratio = landsat.rio.width/landsat.rio.height\nThen, the figure is set up using the aspect ratio, and each figure element is plotted in sequence using the matplotlib package.\n# Setup figure\nfig, ax = plt.subplots(figsize = (6, 6*landsat_aspect_ratio))\n\n# Turn the axis off\nax.axis(\"off\")\n\n# Plot the false color image on the figure\nlandsat[['swir22', 'nir08', 'red']].to_array().plot.imshow(ax = ax,\n                                                        robust = True)\n\n# Add Thomas Fire shapefile as a boundary on the figure\nthomas_fire.boundary.plot(ax = ax,\n                         color = \"black\")\n\n# Add legend to the figure\nax.legend(labels = [\"Fire Boundary\"])\n\n# Add annotation to the figure\nfig.text(0.5, 0.1,\n        'Data Source: CAL FIRE via Data.gov &  Microsof Planetary Computer data catalogue',\n         ha='center', va='center', fontsize=8, color='black', fontstyle='italic')\n\nfig.text(0.395, 0.08, \n         'Date Accessed: 11/19/24',\n         ha='right', va='center', fontsize=8, color='black', fontstyle='italic')\n\n# Add title\nax.set_title(\"Thomas Fire Scar (2017)\", fontsize=14, fontweight='bold')\n\nplt.show()\nOur final figure shows the burn scar of the Thomas Fire, displayed in red and outlined by the fire boundary.\n\n\n\n\n\n\n\nPart 3\nDerived from aqi-analysis.ipynb.\nFirst, import all necessary packages.\nimport pandas as pd\nimport matplotlib.pyplot as plt\nNext, read in the data from the links and concat (stack) the dataframes. Then, clean the column names.\n# Read in data\naqi_17 = pd.read_csv(\"https://aqs.epa.gov/aqsweb/airdata/daily_aqi_by_county_2017.zip\", compression = 'zip')\naqi_18 = pd.read_csv(\"https://aqs.epa.gov/aqsweb/airdata/daily_aqi_by_county_2018.zip\", compression = 'zip')\n\n# Concat the two data frames\naqi = pd.concat([aqi_17, aqi_18])\n\n# Simplify column names\naqi.columns = (aqi.columns\n                  .str.lower()\n                  .str.replace(' ','_'))\nFilter for county “Santa Barbara,” and remove the state_name, county_name, state_code, and county_code columns.\n# Select only data from Santa Barbara County\naqi_sb = aqi[aqi['county_name'] == \"Santa Barbara\"]\n\n# Remove specified columns\naqi_sb = aqi_sb.drop(columns = ['state_name', 'county_name', 'state_code', 'county_code'])\nUpdate the date column to datetime object, and then set it as the index.\n# Update `date` to datetime object\naqi_sb.date = pd.to_datetime(aqi_sb.date)\n\n# Update the index to be the date column\naqi_sb = aqi_sb.set_index('date')\nCalculate the 5-day rolling mean, and add it as a new column.\n# Add AQI 5-day rolling mean to `aqi_sb` data frame\naqi_sb['five_day_average'] = aqi_sb['aqi'].rolling('5D').mean()\nPlot the AQI for Santa Barbara county 2017-2018.\n# Plot AQI and AQI rolling mean \naqi_sb.drop(columns = 'number_of_sites_reporting').plot.line(y = ['aqi', 'five_day_average'])\n\n# Add title\nplt.title(\"AQI in Santa Barbara County 2017-2018\")\n\n# Label x-axis\nplt.xlabel(\"Date\")\n\n# Label y-axis\nplt.ylabel(\"AQI\")\n\n# Add legend\nplt.legend(['AQI', 'Five Day Average'])\n\n\n\n\n\nOur graph clearly shows a spike in AQI at the time of the Thomas Fire.\n\n\n\nReferences\nLandsat data:\nMicrosoft Open Source, Matt McFarland, Rob Emanuele, Dan Morris, & Tom Augspurger. (2022). microsoft/PlanetaryComputer: October 2022 (2022.10.28). Zenodo. https://doi.org/10.5281/zenodo.7261897 Accessed: November 19, 2024\nFire perimeter data:\nState of California, Kimberly Wallin. (2024). CAL FIRE: May 2024 (2024.05.14). https://catalog.data.gov/dataset/california-fire-perimeters-all-b3436 Accessed: November 19, 2024\nAQI Data:\nU.S. Enivornmental Protection Agency. (2024). Air Quality Index Daily Values Report: July 2024 (2024.07.23). https://www.epa.gov/outdoor-air-quality-data/air-quality-index-daily-values-report Accessed: October 22, 2024\n\n\n\n\n\nFootnotes\n\n\nRead more about the Thomas fire here.↩︎\nThis analysis was part of EDS 220: Working with Environmental Datasets - Homework Assignment 4. See the assignment guidelines here.↩︎\nRead more about false color imagery here.↩︎\nThis analysis was part of EDS 220: Working with Environmental Datasets - Homework Assignment 2. See the assignment guidelines here.↩︎"
  },
  {
    "objectID": "posts/2024-12-01-thomas-fire/false-color-analysis.html",
    "href": "posts/2024-12-01-thomas-fire/false-color-analysis.html",
    "title": "Carmen Hoyt",
    "section": "",
    "text": "title: “My First Post” description: “A short catchy description of the blog post.” author: - name: Carmen Hoyt url: https://ceh58.github.io/ affiliation: MEDS affiliation-url: https://bren.ucsb.edu/masters-programs/master-environmental-data-science date: 2024-10-18 categories: [Quarto, MEDS, something-cool] toc: true page-layout: full image: whales.jpg citation: url: https://ceh58.github.io/posts/2024-10-18-my-first-post/ draft: true"
  },
  {
    "objectID": "posts/2024-12-01-thomas-fire/false-color-analysis.html#carmen-hoyt",
    "href": "posts/2024-12-01-thomas-fire/false-color-analysis.html#carmen-hoyt",
    "title": "Carmen Hoyt",
    "section": "Carmen Hoyt",
    "text": "Carmen Hoyt\n\nGitHub Repo\n\n\nAbout:\n\nPurpose:\n\nThe purpose of this task is to use false color imagery to visualize the impact (the burn scar) of the Thomas Fire in 2017.\n\nHighlights:\n\nThis task explores assigning infrared bands to visible colors and plotting shapefiles over the resulting images. Necessary steps include cleaning rasters and matching Coordinate Reference Systems (CRSs).\n\nDataset description:\n\nLandsat Data: Pre-processed, simplified collection of bands (red, green, blue, nir, swir) from Landsat Collection 2 Level-2 (collected by Landsat 8 satellite). Accessed: November 19, 2024\n\nReferences:\n\nLandsat Data: Microsoft Open Source, Matt McFarland, Rob Emanuele, Dan Morris, & Tom Augspurger. (2022). microsoft/PlanetaryComputer: October 2022 (2022.10.28). Zenodo. https://doi.org/10.5281/zenodo.7261897\nFor Fire Perimeter data information, see fire-perimeter.ipynb.\n\nimport os\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport geopandas as gpd\nimport xarray as xr\nimport rioxarray as rioxr\nimport numpy as np"
  },
  {
    "objectID": "posts/2024-12-01-thomas-fire/false-color-analysis.html#true-color-image",
    "href": "posts/2024-12-01-thomas-fire/false-color-analysis.html#true-color-image",
    "title": "Carmen Hoyt",
    "section": "3. True Color Image",
    "text": "3. True Color Image\n\n# a. Import data\nfp = os.path.join(\"/courses/EDS220/data/hwk4_landsat_data\", \"landsat8-2018-01-26-sb-simplified.nc\")\nlandsat = rioxr.open_rasterio(fp)\nlandsat.head(3)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n<xarray.Dataset> Size: 424B\nDimensions:      (band: 1, x: 3, y: 3)\nCoordinates:\n  * band         (band) int64 8B 1\n  * x            (x) float64 24B 1.213e+05 1.216e+05 1.218e+05\n  * y            (y) float64 24B 3.952e+06 3.952e+06 3.952e+06\n    spatial_ref  int64 8B 0\nData variables:\n    red          (band, y, x) float64 72B ...\n    green        (band, y, x) float64 72B ...\n    blue         (band, y, x) float64 72B ...\n    nir08        (band, y, x) float64 72B ...\n    swir22       (band, y, x) float64 72B ...xarray.DatasetDimensions:band: 1x: 3y: 3Coordinates: (4)band(band)int641array([1])x(x)float641.213e+05 1.216e+05 1.218e+05axis :Xcrs :EPSG:32611long_name :x coordinate of projectionresolution :30standard_name :projection_x_coordinateunits :metre_FillValue :nanarray([121305., 121575., 121845.])y(y)float643.952e+06 3.952e+06 3.952e+06axis :Ycrs :EPSG:32611long_name :y coordinate of projectionresolution :-30standard_name :projection_y_coordinateunits :metre_FillValue :nanarray([3952395., 3952125., 3951855.])spatial_ref()int640crs_wkt :PROJCS[\"WGS 84 / UTM zone 11N\",GEOGCS[\"WGS 84\",DATUM[\"WGS_1984\",SPHEROID[\"WGS 84\",6378137,298.257223563]],PRIMEM[\"Greenwich\",0],UNIT[\"degree\",0.0174532925199433,AUTHORITY[\"EPSG\",\"9122\"]],AUTHORITY[\"EPSG\",\"4326\"]],PROJECTION[\"Transverse_Mercator\"],PARAMETER[\"latitude_of_origin\",0],PARAMETER[\"central_meridian\",-117],PARAMETER[\"scale_factor\",0.9996],PARAMETER[\"false_easting\",500000],PARAMETER[\"false_northing\",0],UNIT[\"metre\",1],AXIS[\"Easting\",EAST],AXIS[\"Northing\",NORTH],AUTHORITY[\"EPSG\",\"32611\"]]semi_major_axis :6378137.0semi_minor_axis :6356752.314245179inverse_flattening :298.257223563reference_ellipsoid_name :WGS 84longitude_of_prime_meridian :0.0prime_meridian_name :Greenwichgeographic_crs_name :WGS 84horizontal_datum_name :World Geodetic System 1984projected_crs_name :WGS 84 / UTM zone 11Ngrid_mapping_name :transverse_mercatorlatitude_of_projection_origin :0.0longitude_of_central_meridian :-117.0false_easting :500000.0false_northing :0.0scale_factor_at_central_meridian :0.9996spatial_ref :PROJCS[\"WGS 84 / UTM zone 11N\",GEOGCS[\"WGS 84\",DATUM[\"WGS_1984\",SPHEROID[\"WGS 84\",6378137,298.257223563]],PRIMEM[\"Greenwich\",0],UNIT[\"degree\",0.0174532925199433,AUTHORITY[\"EPSG\",\"9122\"]],AUTHORITY[\"EPSG\",\"4326\"]],PROJECTION[\"Transverse_Mercator\"],PARAMETER[\"latitude_of_origin\",0],PARAMETER[\"central_meridian\",-117],PARAMETER[\"scale_factor\",0.9996],PARAMETER[\"false_easting\",500000],PARAMETER[\"false_northing\",0],UNIT[\"metre\",1],AXIS[\"Easting\",EAST],AXIS[\"Northing\",NORTH],AUTHORITY[\"EPSG\",\"32611\"]]GeoTransform :121170.0 270.0 0.0 3952530.0 0.0 -270.0array(0)Data variables: (5)red(band, y, x)float64...add_offset :0.0coordinates :timescale_factor :1.0_FillValue :0.0[9 values with dtype=float64]green(band, y, x)float64...add_offset :0.0coordinates :timescale_factor :1.0_FillValue :0.0[9 values with dtype=float64]blue(band, y, x)float64...add_offset :0.0coordinates :timescale_factor :1.0_FillValue :0.0[9 values with dtype=float64]nir08(band, y, x)float64...add_offset :0.0coordinates :timescale_factor :1.0_FillValue :0.0[9 values with dtype=float64]swir22(band, y, x)float64...add_offset :0.0coordinates :timescale_factor :1.0_FillValue :0.0[9 values with dtype=float64]Indexes: (3)bandPandasIndexPandasIndex(Index([1], dtype='int64', name='band'))xPandasIndexPandasIndex(Index([121305.0, 121575.0, 121845.0], dtype='float64', name='x'))yPandasIndexPandasIndex(Index([3952395.0, 3952125.0, 3951855.0], dtype='float64', name='y'))Attributes: (0)\n\n\n\n# b. Preliminary exploration\nprint('Sizes of dimensions:', dict(landsat.sizes))\nprint('attrs:', landsat.attrs)\nprint(landsat.dims, landsat.coords)\nlandsat\n\nSizes of dimensions: {'band': 1, 'x': 870, 'y': 731}\nattrs: {}\nFrozenMappingWarningOnValuesAccess({'band': 1, 'x': 870, 'y': 731}) Coordinates:\n  * band         (band) int64 8B 1\n  * x            (x) float64 7kB 1.213e+05 1.216e+05 ... 3.557e+05 3.559e+05\n  * y            (y) float64 6kB 3.952e+06 3.952e+06 ... 3.756e+06 3.755e+06\n    spatial_ref  int64 8B 0\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n<xarray.Dataset> Size: 25MB\nDimensions:      (band: 1, x: 870, y: 731)\nCoordinates:\n  * band         (band) int64 8B 1\n  * x            (x) float64 7kB 1.213e+05 1.216e+05 ... 3.557e+05 3.559e+05\n  * y            (y) float64 6kB 3.952e+06 3.952e+06 ... 3.756e+06 3.755e+06\n    spatial_ref  int64 8B 0\nData variables:\n    red          (band, y, x) float64 5MB ...\n    green        (band, y, x) float64 5MB ...\n    blue         (band, y, x) float64 5MB ...\n    nir08        (band, y, x) float64 5MB ...\n    swir22       (band, y, x) float64 5MB ...xarray.DatasetDimensions:band: 1x: 870y: 731Coordinates: (4)band(band)int641array([1])x(x)float641.213e+05 1.216e+05 ... 3.559e+05axis :Xcrs :EPSG:32611long_name :x coordinate of projectionresolution :30standard_name :projection_x_coordinateunits :metre_FillValue :nanarray([121305., 121575., 121845., ..., 355395., 355665., 355935.])y(y)float643.952e+06 3.952e+06 ... 3.755e+06axis :Ycrs :EPSG:32611long_name :y coordinate of projectionresolution :-30standard_name :projection_y_coordinateunits :metre_FillValue :nanarray([3952395., 3952125., 3951855., ..., 3755835., 3755565., 3755295.])spatial_ref()int640crs_wkt :PROJCS[\"WGS 84 / UTM zone 11N\",GEOGCS[\"WGS 84\",DATUM[\"WGS_1984\",SPHEROID[\"WGS 84\",6378137,298.257223563]],PRIMEM[\"Greenwich\",0],UNIT[\"degree\",0.0174532925199433,AUTHORITY[\"EPSG\",\"9122\"]],AUTHORITY[\"EPSG\",\"4326\"]],PROJECTION[\"Transverse_Mercator\"],PARAMETER[\"latitude_of_origin\",0],PARAMETER[\"central_meridian\",-117],PARAMETER[\"scale_factor\",0.9996],PARAMETER[\"false_easting\",500000],PARAMETER[\"false_northing\",0],UNIT[\"metre\",1],AXIS[\"Easting\",EAST],AXIS[\"Northing\",NORTH],AUTHORITY[\"EPSG\",\"32611\"]]semi_major_axis :6378137.0semi_minor_axis :6356752.314245179inverse_flattening :298.257223563reference_ellipsoid_name :WGS 84longitude_of_prime_meridian :0.0prime_meridian_name :Greenwichgeographic_crs_name :WGS 84horizontal_datum_name :World Geodetic System 1984projected_crs_name :WGS 84 / UTM zone 11Ngrid_mapping_name :transverse_mercatorlatitude_of_projection_origin :0.0longitude_of_central_meridian :-117.0false_easting :500000.0false_northing :0.0scale_factor_at_central_meridian :0.9996spatial_ref :PROJCS[\"WGS 84 / UTM zone 11N\",GEOGCS[\"WGS 84\",DATUM[\"WGS_1984\",SPHEROID[\"WGS 84\",6378137,298.257223563]],PRIMEM[\"Greenwich\",0],UNIT[\"degree\",0.0174532925199433,AUTHORITY[\"EPSG\",\"9122\"]],AUTHORITY[\"EPSG\",\"4326\"]],PROJECTION[\"Transverse_Mercator\"],PARAMETER[\"latitude_of_origin\",0],PARAMETER[\"central_meridian\",-117],PARAMETER[\"scale_factor\",0.9996],PARAMETER[\"false_easting\",500000],PARAMETER[\"false_northing\",0],UNIT[\"metre\",1],AXIS[\"Easting\",EAST],AXIS[\"Northing\",NORTH],AUTHORITY[\"EPSG\",\"32611\"]]GeoTransform :121170.0 270.0 0.0 3952530.0 0.0 -270.0array(0)Data variables: (5)red(band, y, x)float64...add_offset :0.0coordinates :timescale_factor :1.0_FillValue :0.0[635970 values with dtype=float64]green(band, y, x)float64...add_offset :0.0coordinates :timescale_factor :1.0_FillValue :0.0[635970 values with dtype=float64]blue(band, y, x)float64...add_offset :0.0coordinates :timescale_factor :1.0_FillValue :0.0[635970 values with dtype=float64]nir08(band, y, x)float64...add_offset :0.0coordinates :timescale_factor :1.0_FillValue :0.0[635970 values with dtype=float64]swir22(band, y, x)float64...add_offset :0.0coordinates :timescale_factor :1.0_FillValue :0.0[635970 values with dtype=float64]Indexes: (3)bandPandasIndexPandasIndex(Index([1], dtype='int64', name='band'))xPandasIndexPandasIndex(Index([121305.0, 121575.0, 121845.0, 122115.0, 122385.0, 122655.0, 122925.0,\n       123195.0, 123465.0, 123735.0,\n       ...\n       353505.0, 353775.0, 354045.0, 354315.0, 354585.0, 354855.0, 355125.0,\n       355395.0, 355665.0, 355935.0],\n      dtype='float64', name='x', length=870))yPandasIndexPandasIndex(Index([3952395.0, 3952125.0, 3951855.0, 3951585.0, 3951315.0, 3951045.0,\n       3950775.0, 3950505.0, 3950235.0, 3949965.0,\n       ...\n       3757725.0, 3757455.0, 3757185.0, 3756915.0, 3756645.0, 3756375.0,\n       3756105.0, 3755835.0, 3755565.0, 3755295.0],\n      dtype='float64', name='y', length=731))Attributes: (0)\n\n\nThis array has three dimensions, and one band (band) with five variables: red, green, blue, nir08, and swir22. There were no attributes included.\n\n# c. Drop the 'band' dimension\nlandsat = landsat.squeeze().drop_vars('band')\n\n\n# Confirm 'band' was dropped\nprint(landsat.dims, landsat.coords)\n\nFrozenMappingWarningOnValuesAccess({'x': 870, 'y': 731}) Coordinates:\n  * x            (x) float64 7kB 1.213e+05 1.216e+05 ... 3.557e+05 3.559e+05\n  * y            (y) float64 6kB 3.952e+06 3.952e+06 ... 3.756e+06 3.755e+06\n    spatial_ref  int64 8B 0\n\n\n\n# d. Select 'red', 'green', and 'blue' variables and plot\nlandsat[['red', 'green', 'blue']].to_array().plot.imshow()\n\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n\n\n<matplotlib.image.AxesImage at 0x7fd656a5a810>\n\n\n\n\n\n\n# e. Adjust the scale for a true color plot\nlandsat[['red', 'green', 'blue']].to_array().plot.imshow(robust = True)\n\n<matplotlib.image.AxesImage at 0x7fd6550d99d0>\n\n\n\n\n\n\nThe first plot is black and white while the second is in true color. The robust parameter, when set to True, de-weights outliers to properly scale the color bands and produce a colored image."
  },
  {
    "objectID": "posts/2024-12-01-thomas-fire/false-color-analysis.html#false-color-image",
    "href": "posts/2024-12-01-thomas-fire/false-color-analysis.html#false-color-image",
    "title": "Carmen Hoyt",
    "section": "4. False color image",
    "text": "4. False color image\n\n# Create a false color image\nlandsat[['swir22', 'nir08', 'red']].to_array().plot.imshow(robust = True)\n\n<matplotlib.image.AxesImage at 0x7fd65419a290>"
  },
  {
    "objectID": "posts/2024-12-01-thomas-fire/false-color-analysis.html#map",
    "href": "posts/2024-12-01-thomas-fire/false-color-analysis.html#map",
    "title": "Carmen Hoyt",
    "section": "5. Map",
    "text": "5. Map\n\n# Import Thomas Fire shapefile\nthomas_fire = gpd.read_file(os.path.join(\"data\", \"thomas_fire.shp\"))\n\n\n# Make sure CRSs match\nif thomas_fire.crs == landsat.rio.crs:\n    print(\"CRSs match!\")\nelse:\n    landsat = landsat.rio.reproject(thomas_fire.crs)\n    assert landsat.rio.crs == thomas_fire.crs\n    print(\"We matched the CRSs!\")\n\nWe matched the CRSs!\n\n\n\n# a. Map the false color image with the fire perimeter\nlandsat_aspect_ratio = landsat.rio.width/landsat.rio.height\n\nfig, ax = plt.subplots(figsize = (6, 6*landsat_aspect_ratio))\n\nax.axis(\"off\")\n\nlandsat[['swir22', 'nir08', 'red']].to_array().plot.imshow(ax = ax,\n                                                        robust = True)\n\nthomas_fire.boundary.plot(ax = ax,\n                         color = \"black\")\n\nax.legend(labels = [\"Fire Boundary\"])\n\nfig.text(0.5, 0.1,\n        'Data Source: CAL FIRE via Data.gov &  Microsof Planetary Computer data catalogue',\n         ha='center', va='center', fontsize=8, color='black', fontstyle='italic')\n\nfig.text(0.395, 0.08, \n         'Date Accessed: 11/19/24',\n         ha='right', va='center', fontsize=8, color='black', fontstyle='italic')\n\nax.set_title(\"Thomas Fire Scar (2017)\", fontsize=14, fontweight='bold')\n\nplt.show()\n\n\n\n\n\nThis figure shows the burn scar from the Thomas Fire in 2017. By assigning infrared bands to visible colors (short wave infrared to red, near infrared to green, and red to blue), we can easily distinguish the burn scar from the surrounding vegetation. This is because bare earth reflects swir (short wave infrared), appearing red, and healthy vegetation reflects nir (near infrared), appearing green."
  },
  {
    "objectID": "posts.html",
    "href": "posts.html",
    "title": "Blog",
    "section": "",
    "text": "Hurricanes in the Atlantic\n\n\n\nR\n\n\nEDS222\n\n\nStatistics\n\n\n\n\n\n\n\nCarmen Hoyt\n\n\nDec 11, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAnalyzing the Impact of the Thomas Fire in Python\n\n\n\nPython\n\n\nEDS220\n\n\nLandsat\n\n\n\n\n\n\n\nCarmen Hoyt\n\n\nDec 4, 2024\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/2024-12-01-thomas-fire/index.html#footnotes",
    "href": "posts/2024-12-01-thomas-fire/index.html#footnotes",
    "title": "Analyzing the Impact of the Thomas Fire in Python",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nRead more about the Thomas fire here.↩︎\nThis analysis was part of EDS 220: Working with Environmental Datasets - Homework Assignment 4. See the assignment guidelines here.↩︎\nRead more about false color imagery here.↩︎\nThis analysis was part of EDS 220: Working with Environmental Datasets - Homework Assignment 2. See the assignment guidelines here.↩︎"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Carmen Hoyt",
    "section": "",
    "text": "Aloha! My name is Carmen, and I am a student in the Master of Environmental Data Science program at the University of California, Santa Barbara. My journey began on the Gulf Coast of Florida, where I fell in love with the ocean. I was inspired to pursue a B.S. in Biology and a B.S. Earth and Ocean Sciences at Duke University (2018), after which I quite literally “dove” into opportunities to work and travel all over the world. Some of the highlights include aquaculture in Palau, SCUBA instruction in Indonesia and the Turks and Caicos, and environmental consulting in Hawai’i. When I’m not at work, you can find me in the ocean surfing, sailing, or taking underwater photos!"
  },
  {
    "objectID": "index.html#education",
    "href": "index.html#education",
    "title": "Carmen Hoyt",
    "section": "Education",
    "text": "Education\nDuke University, B.S. Biology and B.S. Earth and Ocean Sciences (2018)\nUniversity of California, Santa Barbara Master of Environmental Data Science (2025)"
  },
  {
    "objectID": "index.html#professional-experience",
    "href": "index.html#professional-experience",
    "title": "Carmen Hoyt",
    "section": "Professional Experience",
    "text": "Professional Experience\nBiologist - AECOS, Kane’ohe, Hawai’i (1/23–7/24)\nAt AECOS, I analyzed and visualized environmental data using R, Python, ArcMap and ArcGIS Pro. I conducted natural resource surveys and collected geospatial data using a Trimble Geo 7x and an Autel Evo II drone. I produced technical reports using Microsoft Office and Adobe Acrobat, and I worked with clients to produce deliverables in a timely manner.\nSenior Research Assistant – Oceanic Institute at Hawai’i Pacific University Waimanalo, Hawai’i (6/21–1/23)\nWhile working as a Senior Research Assistant, I managed the algae lab and oversaw the installation and operation of two photobioreactors purchased under a federal grant awarded by the U.S. Department of Education. I collected long-term data, developed lab protocols, and was promoted to Senior Research Assistant for showing leadership and proficiency in all departments. Additionally, I created a marketing role for social media updates and outreach on Instagram and Facebook.\nAssistant Manager/SCUBA Instructor – Atlantic Pro Divers, Jacksonville Beach, Florida (5/20–7/21)\nAs Assistant Manager, I monitored store inventory and formulated business newsletters to support marketing and drive sales. I demonstrated excellent customer service and planned PADI courses. I learned how to balance business expenses with profits, and I was given significant authority in shop decisions. When I wasn’t managing the shop, I was teaching the PADI courses that we offered as a 5-star dive center.\nWaterfront Assistant – School for Field Studies, South Caicos, Turks and Caicos Islands (8/19–5/20)\nThe Waterfront Assistant role with the School for Field Studies in the Turks and Caicos Islands was a 1-year contract that was cut a few months short due to COVID-19. My role during the program was to conduct and supervise field research as well as guide recreational dives and snorkels for college students. I was responsible for operating and maintaining three Carolina Skiffs and assisting SCUBA courses as a PADI Divemaster. When I was not in or on the water, I fulfilled more administrative roles aiding in the smooth operation of everyday life on campus including outreach to the local community.\nOpen Water SCUBA Instructor – PADI, Gili Trawangan, Indonesia (2/19–8/19)\nI worked as a PADI professional (Divemaster and Instructor) in Indonesia, the Turks and Caicos, and Florida. Since this role spanned different countries, I stayed up to date with PADI’s international rules and regulations to ensure quality control over the courses I taught.\nAquaculture Intern – Indigo Seafood Palau, Inc., Koror, Palau (8/18–2/19)\nThis internship my first introduction to aquaculture. I was responsible for the complete larval rearing of coral trout (Plectropomus leopardus) including egg collection, production of live feeds, and hatchery management. I also served as the lead business operator during my time, which included managing finances and other team members.\nLab Technician – Silliman Lab at Duke University Marine Laboratory (8/16–8/17)\nWorking as a summer time Research Technician for the Silliman Lab, I assisted graduate student (now Dr.) Stacy Zhang in the setup and maintenance of large-scale experiments focused on seagrass beds. I was responsible for collecting and recording data both in the field and in the lab in the form of fish surveys and seagrass biomass analysis. I learned crucial steps in the scientific method as well as gained exposure to publications and literature reviews."
  },
  {
    "objectID": "posts/2024-12-10-atlantic-hurricanes/index.html#import-packages",
    "href": "posts/2024-12-10-atlantic-hurricanes/index.html#import-packages",
    "title": "Hurricanes in the Atlantic",
    "section": "Import packages",
    "text": "Import packages\n\n\nExpand Code\n# Load required packages\nlibrary(tidyverse)\nlibrary(janitor)\nlibrary(patchwork)\nlibrary(kableExtra)\nlibrary(webshot2)\nlibrary(here)\n\n\nUsing the above R packages, I begin my analysis by investigating the NA values associated with damage costs (damage_usd). There are 14 in total, and they appear to be proportionally distributed among hurricane categories; so, I decide to remove them."
  },
  {
    "objectID": "posts/2024-12-10-atlantic-hurricanes/index.html#import-data",
    "href": "posts/2024-12-10-atlantic-hurricanes/index.html#import-data",
    "title": "Hurricanes in the Atlantic",
    "section": "Import data",
    "text": "Import data\n\n\nExpand Code\n# Remove scientific notation\noptions(scipen=999)\n\n# Import hurricane data\nhurricane_data &lt;- read_csv(here(\"posts/\", \"2024-12-10-atlantic-hurricanes/\", \"data/\", \"Hurricane Data.csv\"), show_col_types = FALSE) %&gt;%\n  clean_names()\n\n\n\n\nExpand Code\n# Total storms by category\ntotal_storms &lt;- hurricane_data %&gt;%\n  group_by(category) %&gt;%\n  summarise(count = n()) %&gt;%\n  rename(Category = category,\n         Count = count)\n\nprint(paste(\"There are\", sum(is.na(hurricane_data$damage_usd)), \"NA values associated with damage cost.\"))\n\n\n[1] \"There are 14 NA values associated with damage cost.\"\n\n\nExpand Code\n# Check NA values for damage (by category)\nna_storms &lt;- hurricane_data %&gt;%\n  filter(is.na(damage_usd))%&gt;%\n  group_by(category) %&gt;%\n  summarise(count = n()) %&gt;%\n  rename(Category = category,\n         Count = count)\n\nna_table &lt;- left_join(total_storms, na_storms, by = \"Category\") %&gt;%\n  rename(\"Total Storms\" = Count.x,\n         \"NA Damage\" = Count.y) %&gt;%\n  arrange(factor(Category, levels = c('TS', 'Category 1', 'Category 2', 'Category 3', 'Category 4', 'Category 5'))) %&gt;%\n  kbl() %&gt;%\n  kable_styling()\n\nna_table\n\n\n\n\n\nCategory\nTotal Storms\nNA Damage\n\n\n\n\nTS\n55\n11\n\n\nCategory 1\n22\n1\n\n\nCategory 2\n6\n1\n\n\nCategory 3\n7\nNA\n\n\nCategory 4\n21\n1\n\n\nCategory 5\n14\nNA\n\n\n\n\n\n\n\nSince damage costs are reported as high as $140,000,000,000, I decided to scale the damage_usd column to represent millions of dollars and saved this variable as damage_mil.\n\n\nExpand Code\n# Remove rows with NA values for damage costs\nhurricane_data_cleaned &lt;- hurricane_data[!is.na(hurricane_data$damage_usd),]\n\n# Find total number of areas affected\nhurricane_data_cleaned &lt;- hurricane_data_cleaned %&gt;%\n  separate_longer_delim(affected_areas, \",\") %&gt;%\n  group_by(year, name, category, rain_inch, highest_wind_speed, damage_usd, fatalities) %&gt;%\n  summarise(total_areas = n()) %&gt;%\n  # Scale down damage costs\n  mutate(damage_mil = damage_usd/1000000,\n         time = year - 2000)\n\n\nTo test my hypothesis, I will need to calculate the regression coefficient (Beta) associated with time. In order to calculate this sample statistic, I need to develop a model for damage costs. I am primarily interested in the following variables from my dataset:\n\nyear: the year the storm occurred\nrain_inch: rainfall (inches)\nhighest_wind_speed: max wind speed (mph)\ndamage_usd: damage costs in USD\naffected_areas: list of places affected\n\nI chose these variables because they are characteristics of the storm that potentially have a relationship with storm damage costs. While variables such as “fatalities” are likely correlated with damage costs, they are more likely a result of storm intensity rather than a predictor. I also chose to forego category since we are already have a variable for wind speed.\nThe category 5 classification encompasses wind speeds of 157+ mph. As an open-ended category, increased damage costs may be associated with an increasing number of Category 5 storms. More storms will likely be classified as Category 5 due to increasing wind speeds (as a result of increasing storm intensity). So, max wind speed (highest_wind_speed) will likely be the most important predictor in my model. Since rainfall (rain_inch) intensity is also expected to increase with climate change, it will be crucial to include as well.\n\n\nExpand Code\n# Wind speed over time\nwind_time &lt;- ggplot(hurricane_data_cleaned, aes(x = year, y = highest_wind_speed)) +\n  geom_point() +\n  labs(x = \"Year\",\n       y = \"Max Wind Speed (mph)\",\n       title = \"Max Wind Speed over Time\") +\n  geom_hline(yintercept =157,\n             linetype = \"dashed\",\n             color = \"firebrick\") +\n  geom_smooth(method = \"lm\", se = FALSE, linewidth = 1, color = \"cornflowerblue\") +\n  theme_minimal()\n\n# Wind vs. damage\nwind_damage &lt;- ggplot(hurricane_data_cleaned, aes(x = highest_wind_speed, y = damage_mil)) +\n  geom_point() +\n  labs(x = \"Max Wind Speed (mph)\",\n       y = \"Damage Costs (Millions of USD)\",\n       title = \"Damage Costs vs. Max Wind Speed\") +\n  geom_smooth(method = \"lm\", se = FALSE, linewidth = 1, color = \"cornflowerblue\") +\n  theme_minimal()\n\nwind_time / wind_damage\n\n\n\n\n\n\n\n\n\nYou can see how the time period 2000-2014 had 2 category 5 storms while the time period 2015-2023 has 8.\n\n\nExpand Code\n# Rainfall over time\nrain_time &lt;- ggplot(hurricane_data_cleaned, aes(x = year, y = rain_inch)) +\n  geom_point() +\n  labs(x = \"Year\",\n       y = \"Rainfall (in)\",\n       title = \"Rainfall over Time\") +\n  geom_smooth(method = \"lm\", se = FALSE, linewidth = 1, color = \"cornflowerblue\") +\n  theme_minimal()\n\n# Rain vs. damage\nrain_damage &lt;- ggplot(hurricane_data_cleaned, aes(x = rain_inch, y = damage_mil)) +\n  geom_point() +\n  labs(x = \"Rainfall (in)\",\n       y = \"Damage Costs (Millions of USD)\",\n       title = \"Damage Costs vs. Rainfall\") +\n  geom_smooth(method = \"lm\", se = FALSE, linewidth = 1, color = \"cornflowerblue\") +\n  theme_minimal()\n\nrain_time /rain_damage\n\n\n\n\n\n\n\n\n\nI created two new variables to include in the model. The first one measures the number of places affected, total_areas, calculated by counting how many “areas” are listed in the areas_affected column from the original dataset. While it seems intuitive that total_areas may increase over time, that isn’t the case (FIGURE?). However, there is still a relationship between total_areas and damage_mill, so we will include it. The last factor that I am interested in is time. Since we are looking at change over time, and 2000 is the start of the dataset, I calculated the time variable to be the number of years since 2000 that the storm occurred.\n\n\nExpand Code\n# Number of places over time\nplaces_time &lt;- ggplot(hurricane_data_cleaned, aes(x = year, y = total_areas)) +\n  geom_point() +\n  labs(x = \"Year\",\n       y = \"Number of Places Affected\",\n       title = \"Number of Places Affected over Time\") +\n  geom_smooth(method = \"lm\", se = FALSE, linewidth = 1, color = \"cornflowerblue\") +\n  theme_minimal()\n\n# Number of places vs. damage costs\nplaces_damage &lt;- ggplot(hurricane_data_cleaned, aes(x = total_areas, y = damage_mil)) +\n  geom_point() +\n  labs(x = \"Number of Places Affected\",\n       y = \"Damage Costs (Millions of USD)\",\n       title = \"Damage Costs vs. Number of Places Affected\") +\n  geom_smooth(method = \"lm\", se = FALSE, linewidth = 1, color = \"cornflowerblue\") +\n  theme_minimal()\n\nplaces_time / places_damage\n\n\n\n\n\n\n\n\n\n\n\nExpand Code\n# Damage costs over time\nggplot(hurricane_data_cleaned, aes(x = time, y = damage_mil)) +\n  geom_point() +\n  labs(x = \"Time (Years since 2000)\",\n       y = \"Damage Costs (Millions of USD)\",\n       title = \"Damage Costs vs. Time\") +\n  geom_smooth(method = \"lm\", se = FALSE, linewidth = 1, color = \"cornflowerblue\") +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\nThe multiple regression equation that I settled on is:\ndamage_mil~highest_wind_speed + rain_inch + total_areas + time\ndamage_mil = Beta 0 + Beta 1 * wind speed + Beta 2 * rainfall + Beta 3 * number of places affected + Beta 4 * time\n\n\nExpand Code\n# Create the model\ndamage_model &lt;- lm(damage_mil ~ highest_wind_speed + rain_inch + total_areas + time, data = hurricane_data_cleaned)\nsummary(damage_model)\n\n\n\nCall:\nlm(formula = damage_mil ~ highest_wind_speed + rain_inch + total_areas + \n    time, data = hurricane_data_cleaned)\n\nResiduals:\n   Min     1Q Median     3Q    Max \n-26812  -8091  -3670   3719  92553 \n\nCoefficients:\n                    Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)        -21877.43    5970.28  -3.664 0.000389 ***\nhighest_wind_speed    175.69      43.61   4.029 0.000106 ***\nrain_inch             610.73     215.81   2.830 0.005571 ** \ntotal_areas            70.82     604.22   0.117 0.906920    \ntime                  377.55     261.77   1.442 0.152163    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 18530 on 106 degrees of freedom\nMultiple R-squared:  0.2332,    Adjusted R-squared:  0.2042 \nF-statistic: 8.057 on 4 and 106 DF,  p-value: 0.00001036\n\n\nUsing this model, I calculated the regression coefficients (Beta 1, Beta 2, Beta 3, and Beta 4) and their associated p-values.\n\n\nExpand Code\n# p-values\nbeta1_p &lt;- summary(damage_model)$coefficients[2,4]\nbeta2_p &lt;- summary(damage_model)$coefficients[3,4]\nbeta3_p &lt;- summary(damage_model)$coefficients[4,4]\nbeta4_p &lt;- summary(damage_model)$coefficients[5,4]\n\nbeta &lt;- c(beta1_p, beta2_p, beta3_p, beta4_p)\n\n# Print p-values\nfor (i in seq_along(beta)) {\n  print(paste0(\"The p-value for Beta \", i, \" is \", beta[i], \".\"))\n}\n\n\n[1] \"The p-value for Beta 1 is 0.000105720738882069.\"\n[1] \"The p-value for Beta 2 is 0.00557054755522526.\"\n[1] \"The p-value for Beta 3 is 0.906919636226243.\"\n[1] \"The p-value for Beta 4 is 0.152163328387691.\"\n\n\nTo visualize damage predictions by the model, I looked at damage costs over time by wind speeds (broken down by category) and by rainfall (by quantiles). To visualize damage predictions by wind speed, I held rainfall and total areas constant at their mean values. To visualize damage predictions by rainfall quantile, I held wind speed and total areas constant at their mean values.\n\n\nExpand Code\n# Update model\npredictions &lt;- expand_grid(\n  highest_wind_speed = c(74, 96, 111, 130, 157),\n  rain_inch = mean(hurricane_data_cleaned$rain_inch),\n  total_areas = mean(hurricane_data_cleaned$total_areas),\n  time = seq(0, 23, length.out = 100)) %&gt;%\n  mutate(damage_predicted = predict(damage_model, \n                                      newdata = .,\n                                      type = \"response\"))\n\n#Visualize\nggplot(predictions, aes(time, damage_predicted, color = factor(highest_wind_speed))) +\n  geom_line() +\n  scale_color_brewer(palette = \"Reds\",\n                     name =\"Wind Speed (mph)\",\n                   labels = c(\"74 (Cat 1)\", \"96 (Cat 2)\", \"111 (Cat 3)\", \"130 (Cat 4)\", \"157 (Cat 5)\")) +\n   labs(x = \"Years Since 2000\",\n       y = \"Predicted Damage Costs (Millions of USD)\",\n       title = \"Predicted Damage Costs over Time by Wind Speed\") +\n  theme_bw()\n\n\n\n\n\n\n\n\n\n\n\nExpand Code\n# Update model\npredictions3 &lt;- expand_grid(\n  highest_wind_speed = mean(hurricane_data_cleaned$highest_wind_speed),\n  rain_inch = c(quantile(hurricane_data_cleaned$rain_inch)[2],\n                   quantile(hurricane_data_cleaned$rain_inch)[3],\n                   quantile(hurricane_data_cleaned$rain_inch)[4]),\n  total_areas = mean(hurricane_data_cleaned$total_areas),\n  time = seq(0, 23, length.out = 100)) %&gt;%\n  mutate(damage_predicted = predict(damage_model, \n                                      newdata = .,\n                                      type = \"response\"))\n\n# Visualize\nggplot(predictions3, aes(time, damage_predicted, color = factor(rain_inch))) +\n  geom_line() +\n  scale_color_brewer(palette = \"Reds\",\n                     name =\"Rainfall (in)\") +\n   labs(x = \"Years Since 2000\",\n       y = \"Predicted Damage Costs (Millions of USD)\",\n       title = \"Predicted Damage Costs over Time by Rainfall Quantiles\") +\n  theme_bw()"
  },
  {
    "objectID": "posts/2024-12-10-atlantic-hurricanes/index.html#footnotes",
    "href": "posts/2024-12-10-atlantic-hurricanes/index.html#footnotes",
    "title": "Hurricanes in the Atlantic",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nHurricane season runs June 1 to November 30, but since 2021, the National Hurricane Center (NHC) has considered moving the start date to May 15 to encompass increasing early-season activity.↩︎\nRead more about how hurricanes are expected to evolve with climate change here.↩︎\nRead more about the Saffir-Simpson scale here.↩︎\nRead more about Hurricane Ian here.↩︎"
  },
  {
    "objectID": "posts/2024-12-10-atlantic-hurricanes/index.html#visualize",
    "href": "posts/2024-12-10-atlantic-hurricanes/index.html#visualize",
    "title": "Hurricanes in the Atlantic",
    "section": "Visualize",
    "text": "Visualize\nA closer look at damage costs over the years.\n\n\nExpand Code\n# Damage costs over time\nggplot(hurricane_data_cleaned, aes(x = year, y = damage_mil)) +\n  geom_point() +\n  labs(x = \"Year\",\n       y = \"Damage (Millions of USD)\",\n       title = \"Damage Costs 2000-2023\") +\n  geom_smooth(method = \"lm\", se = FALSE, linewidth = 1) +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\nLet’s break down damage costs over the years by category.\n\n\nExpand Code\n# Cost of damage over time\nggplot(hurricane_data_cleaned, aes(x = year, y = damage_mil, color = factor(category, levels = c(\"TS\", \"Category 1\", \"Category 2\", \"Category 3\", \"Category 4\", \"Category 5\"), labels = c(\"TS\", \"1\", \"2\", \"3\", \"4\", \"5\")))) +\n  geom_point() +\n  labs(x = \"Year\",\n       y = \"Damage (Millions of USD)\",\n       title = \"Damage Costs 2000-2023 by Category\",\n       color = \"Category\") +\n  geom_smooth(method = \"lm\", se = FALSE, linewidth = 1) +\n  scale_color_brewer(palette = \"Reds\") +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\nSince category 5 storms include wind speeds of 157+ mph, it is possible that increasing damage costs are associated with an increasing number of category 5 storms. The open-ended category will amass more storms as max wind speeds are expected to increase over time.\n\n\nExpand Code\n# Wind speed over time\nggplot(hurricane_data_cleaned, aes(x = year, y = highest_wind_speed)) +\n  geom_point() +\n  labs(x = \"Year\",\n       y = \"Max Wind Speed (mph)\",\n       title = \"Max Wind Speed 2000-2023\") +\n  geom_hline(yintercept =157,\n             linetype = \"dashed\",\n             color = \"red\") +\n  geom_smooth(method = \"lm\", se = FALSE, linewidth = 1) +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\nYou can see how the time period 2000-2014 had 2 category 5 storms while the time period 2015-2023 has 8. Since rainfall is also expected to increase with climate change, we might want to include it in our model.\n\n\nExpand Code\n# Rainfall over time\nggplot(hurricane_data_cleaned, aes(x = year, y = rain_inch)) +\n  geom_point() +\n  labs(x = \"Year\",\n       y = \"Rainfall (in)\",\n       title = \"Rainfall 2000-2023\") +\n  geom_smooth(method = \"lm\", se = FALSE, linewidth = 1) +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\nSo far max wind speed and rainfall are interesting potential factors that are likely driving storm damage costs. Let’s take a look at their individual relationships with damage costs.\n\n\nExpand Code\n# Rainfall over time\nwind_damage &lt;- ggplot(hurricane_data_cleaned, aes(x = highest_wind_speed, y = damage_mil)) +\n  geom_point() +\n  labs(x = \"Max Wind Speed\",\n       y = \"Damage Costs (Millions of USD)\",\n       title = \"Damage Costs vs. Wind\") +\n  geom_smooth(method = \"lm\", se = FALSE, linewidth = 1) +\n  theme_minimal()\n\nrain_damage &lt;- ggplot(hurricane_data_cleaned, aes(x = rain_inch, y = damage_mil)) +\n  geom_point() +\n  labs(x = \"Rainfall (in)\",\n       y = \"Damage Costs (Millions of USD)\",\n       title = \"Damage Costs vs. Rainfall\") +\n  geom_smooth(method = \"lm\", se = FALSE, linewidth = 1) +\n  theme_minimal()\n\nwind_damage / rain_damage\n\n\n\n\n\n\n\n\n\nThe last factor that may be playing a role in damage costs is the number of places affected, calculated by counting how many “areas” are listed in the areas_affected column from the original dataset. As storms increase in intensity, I would expect that they will impact more places. Thus, we will explore a potential relationship between number of places affected and damage costs.\n\n\nExpand Code\n# Number of palces over time\nggplot(hurricane_data_cleaned, aes(x = year, y = total_areas)) +\n  geom_point() +\n  labs(x = \"Year\",\n       y = \"Number of Places Affected\",\n       title = \"Number of Places Affected 2000-2023\") +\n  geom_smooth(method = \"lm\", se = FALSE, linewidth = 1) +\n  theme_minimal()\n\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\nExpand Code\n# Number of places vs. damage costs\nggplot(hurricane_data_cleaned, aes(x = total_areas, y = damage_mil)) +\n  geom_point() +\n  labs(x = \"Number of Places Affected\",\n       y = \"Damage Costs (Millions of USD)\",\n       title = \"Damage Costs vs. Number of Places Affected\") +\n  geom_smooth(method = \"lm\", se = FALSE, linewidth = 1) +\n  theme_minimal()\n\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\nWe will explore this more in the next section.\n\n\nExpand Code\n# Cost of damage by category\nggplot(hurricane_data_cleaned, aes(x = factor(category, levels = c(\"TS\", \"Category 1\", \"Category 2\", \"Category 3\", \"Category 4\", \"Category 5\"), labels = c(\"TS\", \"1\", \"2\", \"3\", \"4\", \"5\")), y = damage_mil)) +\n  geom_boxplot() +\n  labs(x = \"Category\",\n       y = \"Damage (Millions of USD)\",\n       title = \"Cost of Storm Damage by Category 2000-2023\") +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\nExpand Code\nmean_median &lt;- hurricane_data_cleaned %&gt;%\n  group_by(category) %&gt;%\n  summarise(median = median(damage_usd/1000000),\n            mean = mean(damage_usd/1000000)) %&gt;%\n  arrange(factor(category, levels = c('TS', 'Category 1', 'Category 2', 'Category 3', 'Category 4', 'Category 5'))) %&gt;%\n  rename(Category = category,\n         \"Median Damage Costs\" = median,\n         \"Mean Damage Costs\" = mean) %&gt;%\n  kbl() %&gt;%\n  kable_styling()\n\nmean_median\n\n\n\n\n\nCategory\nMedian Damage Costs\nMean Damage Costs\n\n\n\n\nTS\n19.8\n413.0023\n\n\nCategory 1\n181.0\n496.8541\n\n\nCategory 2\n1520.0\n1181.7400\n\n\nCategory 3\n4400.0\n13729.6143\n\n\nCategory 4\n3345.0\n13474.4100\n\n\nCategory 5\n4550.0\n26297.3571\n\n\n\n\n\n\n\nThe damage costs data appear to be right-skewed across all hurricane categories. Mean damage costs are higher than median damage costs due to more weight/outliers on the right tail (high end) of the observations. Thus, we may want to log-transform these data."
  },
  {
    "objectID": "posts/2024-12-10-atlantic-hurricanes/index.html",
    "href": "posts/2024-12-10-atlantic-hurricanes/index.html",
    "title": "Hurricanes in the Atlantic",
    "section": "",
    "text": "For more information, visit my GitHub Repository."
  },
  {
    "objectID": "posts/2024-12-10-atlantic-hurricanes/index.html#multiple-regression-model",
    "href": "posts/2024-12-10-atlantic-hurricanes/index.html#multiple-regression-model",
    "title": "Hurricanes in the Atlantic",
    "section": "Multiple Regression Model",
    "text": "Multiple Regression Model\n\n\nExpand Code\n# Create the model\ndamage_model &lt;- lm(damage_mil ~ highest_wind_speed + rain_inch + total_areas + time, data = hurricane_data_cleaned)\nsummary(damage_model)\n\n\n\nCall:\nlm(formula = damage_mil ~ highest_wind_speed + rain_inch + total_areas + \n    time, data = hurricane_data_cleaned)\n\nResiduals:\n   Min     1Q Median     3Q    Max \n-26812  -8091  -3670   3719  92553 \n\nCoefficients:\n                    Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)        -21877.43    5970.28  -3.664 0.000389 ***\nhighest_wind_speed    175.69      43.61   4.029 0.000106 ***\nrain_inch             610.73     215.81   2.830 0.005571 ** \ntotal_areas            70.82     604.22   0.117 0.906920    \ntime                  377.55     261.77   1.442 0.152163    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 18530 on 106 degrees of freedom\nMultiple R-squared:  0.2332,    Adjusted R-squared:  0.2042 \nF-statistic: 8.057 on 4 and 106 DF,  p-value: 0.00001036\n\n\n\nExtract p-values\n\n\nExpand Code\n# p-values\nbeta1_p &lt;- summary(damage_model)$coefficients[2,4]\nbeta2_p &lt;- summary(damage_model)$coefficients[3,4]\nbeta3_p &lt;- summary(damage_model)$coefficients[4,4]\nbeta4_p &lt;- summary(damage_model)$coefficients[5,4]\n\nbeta &lt;- c(beta1_p, beta2_p, beta3_p, beta4_p)\n\n# Print p-values\nfor (i in seq_along(beta)) {\n  print(paste0(\"The p-value for Beta \", i, \" is \", beta[i], \".\"))\n}\n\n\n[1] \"The p-value for Beta 1 is 0.000105720738882069.\"\n[1] \"The p-value for Beta 2 is 0.00557054755522526.\"\n[1] \"The p-value for Beta 3 is 0.906919636226243.\"\n[1] \"The p-value for Beta 4 is 0.152163328387691.\"\n\n\nNow, let’s visualize these relationships. Using mean rainfall and mean number of places affected, we can look at the relationship between time and damage costs by wind speed.\n\n\nExpand Code\n# Update model\npredictions &lt;- expand_grid(\n  highest_wind_speed = c(74, 96, 111, 130, 157),\n  rain_inch = mean(hurricane_data_cleaned$rain_inch),\n  total_areas = mean(hurricane_data_cleaned$total_areas),\n  time = seq(0, 23, length.out = 100)) %&gt;%\n  mutate(damage_predicted = predict(damage_model, \n                                      newdata = .,\n                                      type = \"response\"))\n\n#Visualize\nggplot(predictions, aes(time, damage_predicted, color = factor(highest_wind_speed))) +\n  geom_line() +\n  scale_color_brewer(palette = \"Reds\",\n                     name =\"Wind Speed (mph)\",\n                   labels = c(\"74 (Cat 1)\", \"96 (Cat 2)\", \"111 (Cat 3)\", \"130 (Cat 4)\", \"157 (Cat 5)\")) +\n   labs(x = \"Years Since 2000\",\n       y = \"Predicted Damage Costs (Millions of USD)\",\n       title = \"Predicted Damage Costs over Time by Wind Speed\") +\n  theme_bw()\n\n\n\n\n\n\n\n\n\n\n\nExpand Code\n# Update model\npredictions3 &lt;- expand_grid(\n  highest_wind_speed = mean(hurricane_data_cleaned$highest_wind_speed),\n  rain_inch = c(quantile(hurricane_data_cleaned$rain_inch)[2],\n                   quantile(hurricane_data_cleaned$rain_inch)[3],\n                   quantile(hurricane_data_cleaned$rain_inch)[4]),\n  total_areas = mean(hurricane_data_cleaned$total_areas),\n  time = seq(0, 23, length.out = 100)) %&gt;%\n  mutate(damage_predicted = predict(damage_model, \n                                      newdata = .,\n                                      type = \"response\"))\n\n# Visualize\nggplot(predictions3, aes(time, damage_predicted, color = factor(rain_inch))) +\n  geom_line() +\n  scale_color_brewer(palette = \"Reds\",\n                     name =\"Rainfall (in)\") +\n   labs(x = \"Years Since 2000\",\n       y = \"Predicted Damage Costs (Millions of USD)\",\n       title = \"Predicted Damage Costs over Time by Rainfall Quantiles\") +\n  theme_bw()\n\n\n\n\n\n\n\n\n\n\n\nExpand Code\n# Update model\npredictions4 &lt;- expand_grid(\n  highest_wind_speed = mean(hurricane_data_cleaned$highest_wind_speed),\n  rain_inch = mean(hurricane_data_cleaned$rain_inch),\n  total_areas = seq(min(hurricane_data_cleaned$total_areas),\n                   max(hurricane_data_cleaned$total_areas),\n                   by = 5),\n  time = seq(0, 23, length.out = 100)) %&gt;%\n  mutate(damage_predicted = predict(damage_model, \n                                      newdata = .,\n                                      type = \"response\"))\n\n# Visualize\nggplot(predictions4, aes(time, damage_predicted, color = factor(total_areas))) +\n  geom_line() +\n  scale_color_brewer(palette = \"Reds\",\n                      name =\"Number of Places\") +\n   labs(x = \"Years Since 2000\",\n       y = \"Predicted Damage Costs (Millions of USD)\",\n       title = \"Predicted Damage Costs over Time by Places\") +\n  theme_bw()"
  },
  {
    "objectID": "posts/2024-12-10-atlantic-hurricanes/index.html#multiple-regression-model-1",
    "href": "posts/2024-12-10-atlantic-hurricanes/index.html#multiple-regression-model-1",
    "title": "Hurricanes in the Atlantic",
    "section": "Multiple Regression Model",
    "text": "Multiple Regression Model\n\n\nExpand Code\n# Create the model\nlog_damage_model &lt;- lm(log(damage_mil) ~ highest_wind_speed + rain_inch + total_areas, data = hurricane_data_cleaned)\nsummary(log_damage_model)\n\n\n\nCall:\nlm(formula = log(damage_mil) ~ highest_wind_speed + rain_inch + \n    total_areas, data = hurricane_data_cleaned)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-16.1657  -2.2443   0.7009   2.2750   6.7068 \n\nCoefficients:\n                    Estimate Std. Error t value      Pr(&gt;|t|)    \n(Intercept)        -2.664221   0.951295  -2.801       0.00605 ** \nhighest_wind_speed  0.049082   0.007673   6.397 0.00000000427 ***\nrain_inch           0.096864   0.038346   2.526       0.01300 *  \ntotal_areas         0.271875   0.105602   2.575       0.01140 *  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 3.307 on 107 degrees of freedom\nMultiple R-squared:  0.3936,    Adjusted R-squared:  0.3766 \nF-statistic: 23.15 on 3 and 107 DF,  p-value: 0.00000000001263\n\n\n\nBeta 1: Max Wind Speed\n\n\nExpand Code\n# Distribution of Beta1\nbeta1_estimate &lt;- summary(log_damage_model)$coefficients[2, 1]\nbeta1_se &lt;- summary(log_damage_model)$coefficients[2, 2]\n\n# Under null hypothesis\ntibble(beta1 = seq(-(beta1_estimate + beta1_se),\n                   beta1_estimate + beta1_se,\n                   length.out = 200),\n       density = dnorm(beta1, mean = 0, sd = beta1_se)) %&gt;% \n  # Visualize\n  ggplot(aes(beta1, density)) +\n  geom_line(color = \"cornflowerblue\") +\n  geom_vline(xintercept = beta1_estimate, color = \"firebrick\") +\n  labs(x = \"Beta 1\",\n       y = \"Density\") +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\nCalculate the probability of the point estimate under the null:\n\n\nExpand Code\n# p-value for Beta1\npval_beta1 &lt;- 2 * pnorm(-abs(beta1_estimate), mean = 0, sd = beta1_se)\nprint(paste0(\"The p-value for Beta 1 is: \", pval_beta1, \".\"))\n\n\n[1] \"The p-value for Beta 1 is: 0.000000000158450295997746.\"\n\n\n\n\nBeta 2: Rainfall\n\n\nExpand Code\n# Distribution of Beta2\nbeta2_estimate &lt;- summary(log_damage_model)$coefficients[3, 1]\nbeta2_se &lt;- summary(log_damage_model)$coefficients[3, 2]\n\n# Visualize\ntibble(beta2 = seq(-(beta2_estimate + beta2_se),\n                   beta2_estimate + beta2_se,\n                   length.out = 200),\n       density = dnorm(beta2, mean = 0, sd = beta2_se)) %&gt;% \n  ggplot(aes(beta2, density)) +\n  geom_line(color = \"cornflowerblue\") +\n  geom_vline(xintercept = beta2_estimate, color = \"firebrick\") +\n  labs(x = \"Beta 2\",\n       y = \"Density\") +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\nCalculate the probability of the point estimate under the null:\n\n\nExpand Code\n# p-value for Beta1\npval_beta2 &lt;- 2 * pnorm(-abs(beta2_estimate), mean = 0, sd = beta2_se)\nprint(paste0(\"The p-value for Beta 2 is: \", pval_beta2, \".\"))\n\n\n[1] \"The p-value for Beta 2 is: 0.0115355894798932.\"\n\n\n\n\nBeta 3: Number of Places Affected\n\n\nExpand Code\n# Distribution of Beta2\nbeta3_estimate &lt;- summary(log_damage_model)$coefficients[4, 1]\nbeta3_se &lt;- summary(log_damage_model)$coefficients[4, 2]\n\n# Visualize\ntibble(beta3 = seq(-(beta3_estimate + beta3_se),\n                   beta3_estimate + beta3_se,\n                   length.out = 200),\n       density = dnorm(beta3, mean = 0, sd = beta3_se)) %&gt;% \n  ggplot(aes(beta3, density)) +\n  geom_line(color = \"cornflowerblue\") +\n  geom_vline(xintercept = beta2_estimate, color = \"firebrick\") +\n  labs(x = \"Beta 3\",\n       y = \"Density\") +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\nCalculate the probability of the point estimate under the null:\n\n\nExpand Code\n# p-value for Beta1\npval_beta3 &lt;- 2 * pnorm(-abs(beta3_estimate), mean = 0, sd = beta3_se)\nprint(paste0(\"The p-value for Beta 3 is: \", pval_beta3, \".\"))\n\n\n[1] \"The p-value for Beta 3 is: 0.01003749078959.\""
  },
  {
    "objectID": "posts/2024-12-10-atlantic-hurricanes/index.html#conclusions",
    "href": "posts/2024-12-10-atlantic-hurricanes/index.html#conclusions",
    "title": "Hurricanes in the Atlantic",
    "section": "Conclusions",
    "text": "Conclusions\nI found that the p-values for Beta 1 (hightest_wind_speed) and Beta 2 (rain_inch) were less than \\(alpha=0.05\\).\nBeta 3 (total_areas) and Beta 4 (time) were greater than \\(alpha=0.05\\).\nWhile we cannot confirm that damage costs are affected by wind speed or rainfall, we can rule out that their influence is due to random chance.\nAs for time, we failed to reject the null hypothesis:\n\nH0: Time has no effect on storm damage costs.\n\nSo, to conclude, I could not rule out that the effect of time on damage_mil could be due to random chance.\nThere are a few factors are not considered in these models, such as the effects of inflation. There is likely an interaction between time and inflation,\nAdditional predictor variables that would be of interest:\n\nstorm surge\nwater temperature"
  },
  {
    "objectID": "posts/2024-12-10-atlantic-hurricanes/index.html#next-steps",
    "href": "posts/2024-12-10-atlantic-hurricanes/index.html#next-steps",
    "title": "Hurricanes in the Atlantic",
    "section": "Next steps",
    "text": "Next steps\nGiven more time, I would have been interested in compiling a better dataset. The dataset used in this analysis isn’t the best (no original source or thorough descriptions of variables i.e. rainfall?).\nhttps://www.ncei.noaa.gov/access/billions/"
  },
  {
    "objectID": "posts/2024-12-10-atlantic-hurricanes/index.html#conclusions-1",
    "href": "posts/2024-12-10-atlantic-hurricanes/index.html#conclusions-1",
    "title": "Hurricanes in the Atlantic",
    "section": "Conclusions",
    "text": "Conclusions\nI found that the p-values for Beta 1 (hightest_wind_speed) and Beta 2 (rain_inch) were less than \\(alpha=0.05\\).\nBeta 3 (total_areas) and Beta 4 (time) were greater than \\(alpha=0.05\\).\nWhile we cannot confirm that damage costs are affected by wind speed or rainfall, we can rule out that their influence is due to random chance.\nAs for time, we failed to reject the null hypothesis:\n\nH0: Time has no effect on storm damage costs.\n\nSo, to conclude, I could not rule out that the effect of time on damage_mil could be due to random chance.\nThere are a few factors are not considered in these models, such as the effects of inflation. There is likely an interaction between time and inflation,\nAdditional predictor variables that would be of interest:\n\nstorm surge\nwater temperature"
  }
]